# Statistiek #

Als er een onderdeel is dat studenten van verschillende opleidingen verbindt is het wel de 
vrees voor (het gebrek aan kennis over) statistiek. En toch is het in elke wetenschappelijke 
discipline een cruciaal onderdeel omdat het de sleutel is tot het trekken van conclusies uit 
verzamelde gegevens. Wat is de 'waarheid' die verborgen ligt in de data en hoe kunnen 
verschillende hypotheses tegen elkaar afgewogen worden. In deze module zullen we aan de 
hand van een verzonnen casus een paar van de meest voorkomende technieken bekijken.

![](ExampleDenemarken.png){:.inline}{: style="width:35%"}

**De casus:** In Denemarken is een onderzoeksgroep gaan bestuderen of de lengte van vrouwen 
gecorreleerd is met het inkomen van hun ouders. De inkomenscategorie&euml;n lopen van 
categorie-0 (zeer arm) tot categorie-10 (zeer rijk) en in elke categorie is een willekeurig 
aantal vrouwen geselecteerd van wie de lengte is gemeten. De data (de gemeten gemiddelde lengte 
voor elke inkomenscategorie) is weergegeven in de grafiek hiernaast. En hier beginnen de problemen.
Een deel van de onderzoekers vindt dat de data suggereert dat er een duidelijk lineair 
verband te zien is (blauw) terwijl een andere groep vindt dat er helemaal geen afhankelijkheid 
is (rood). Die laatste groep zegt dat de geobserveerde lichte afhankelijkheid gewoon het resultaat 
van de toevallige fluctuaties in de lengte van vrouwen die in de steekproeven geselecteerd zijn. 

We gaan in deze module na een paar korte inleidende oefeningen proberen te achterhalen welke 
conclusies we kunnen trekken: is er nou wel of niet een (al dan niet causaal) verband?

Hoewel het niet de bedoeling is om hier een volledig statistiek college te verzorgen zullen we er 
niet aan ontkomen om naast een aantal nieuwe Python ingredienten ook wat statistiek te introduceren 
in de voorbereiding op een opdracht.
 
## Opdracht 1: percentage vrouwen dat langer is dan de gemiddelde man

In de eerste opdracht zullen we de vraag beantwoorden welk percentage van de vrouwen in Nederland langer 
is dan de gemiddelde man. Voor deze opdracht is het concept normaalverdeling en het manipuleren 
daarvan in Python erg belangrijk.

#### Statistiek info voor opdracht 1:  de normaalverdeling 

In de natuur komt overal variatie voor: de lengte van mensen in een land, of het gewicht van 
dieren in een populatie om er maar een paar te noemen. De verdeling die de relatieve frequentie 
beschrijft waarmee een specifieke waarde $$x$$ voorkomt in de populatie van metingen wordt beschreven 
volgens de zogenaamde normaalverdeling:

$$ f(x,|\mu,\sigma) = \frac{1}{\sigma\sqrt{2\pi}} exp^{-\frac{1}{2}\left( \frac{x-\mu}{\sigma} \right)^2}$$

![](ExampleLengte.png){:.inline}{: style="width:35%"}

Deze verdeling, ook wel de Gaussische distributie genoemd, wordt gekarakteriseerd door maar 
twee parameters: het gemiddelde ($$\mu$$) en de maat voor de spreiding ($$\sigma$$). Er geldt 
dat ongeveer 68%(95%) van de waarden in het gebied $$\mu \pm 1\sigma$$ ($$\mu \pm 2\sigma$$) ligt.

De lengte van mannen (vrouwen) in Nederland wordt bijvoorbeeld beschreven door een normaalverdeling 
met een gemiddelde $$\mu$$ = 184.0 (170.6) cm en breedte $$\sigma$$ = 7.0 (6.5) cm.  Dit betekent 
dat 34% van de mannen langer is dan 191 cm en dan 2.5% van de vrouwen kleiner is dan 157.6 cm. 
De (genormeerde) grafieken van de twee verdelingen staan in grafiek hiernaast.

<br>

#### Python info voor opdracht 1: random getallen uit een normaalverdeling 

We hebben eerder gezien hoe je een random getal trekt in Python tussen 0 en 1. Het is ook mogelijk 
om een random getal te trekken uit een bepaalde verdeling en omdat de normaalverdeling zo'n prominente 
plek inneemt is daar een standaard functie voor in Python (in de `numpy` bibliotheek) met de volgende 
syntax:

{: .language-python}
    gemiddelde = 170.6
    breedte = 6.5
    lengte = numpy.random.normal(gemiddelde,breedte)

Als je dit heel vaak herhaalt zullen de waardes van $$x$$ verdeeld zijn volgens de rode grafiek 
hierboven.

#### Opdracht 1: verdeling lengtes van alle vrouwen

Schrijf een programma `statistiek_opdracht1.py()` waarin je 1 miljoen random getallen trekt uit de 
normaalverdeling die de lengte van vrouwen in Nederland beschrijft. Maak een grafiek van 
al deze random lengtes. Gebruik hiervoor een histogram met bins die elk een breedte van 
0.5 cm hebben. Hou bij het trekken van de random lengtes bij hoeveel vrouwen een lengte 
hebben die groter is dan die van de gemiddelde man. Print aan het eind van het programma 
dit percentage lange vrouwen met 2 decimalen nauwkeurigheid.

{: .language-python}
    Het percentage lange vrouwen (langer dan 184 cm) is X.XX procent


## Opdracht 2: hoe representatief is een steekproef

In de echte wereld kunnen we vaak helaas niet alles weten. We kunnen niet van elke vrouw in Nederland 
precies achterhalen hoe lang ze is, net zoals Maurice de Hond niet van elke Nederlander weet 
op welke politieke partij hij of zij zal stemmen. We kunnen wel met behulp van steekproeven 
proberen een idee te krijgen van de hele populatie: we bepalen de lengtes van een groep 
vrouwen of de politieke voorkeuren van een groep Nederlanders en maken daarmee een schatting 
van de eigenschappen van de volledige populatie. 

We gaan in deze opdracht onderzoeken hoeveel nauwkeuriger de schatting van het 'echte' gemiddelde 
is bij een toenemend aantal mensen in de steekproef door met behulp van de computer nep-steekproeven 
te nemen. We selecteren dus random waardes uit de oorspronkelijke 'echte' distributie. Door van 
elk van deze steekproeven de gemiddelde lengte te bekijken kunnen we bekijken hoe vaak zo'n 
steekproef in de buurt zit van de echte waarde en hoe dit percentage afhangt van het aantal mensen 
in de steekproef zelf.

#### Opdracht 2: impact van meer metingen op de nauwkeurigheid

Schrijf een programma `statistiek_opdracht2.py` dat uitrekent welk percentage van groepen vrouwen 
(steekproeven) meer dan 5 cm afwijkt van het echte gemiddelde (170.6 cm). Doe dit voor 
verschillende groottes van de steekproef (het aantal mensen in de steekproef): $$N=2,3,5,10,100$$. 

Volg voor het bepalen van de fractie voor een specifieke waarde van $$N$$ het volgende 
stappenplan:

  - Trek N random waardes uit de oorspronkelijke verdeling: een steekproef
  - Bepaal voor elke steekproef het gemiddelde van de lengtes van de vrouwen 
    in die groep en bewaar die
  - Herhaal dit voor een groot aantal steekproeven (100000 bijvoorbeeld)
  - Hou bij in hoeveel steekproeven het gemiddelde meer dan 5 cm afwijkt 
    van het 'echte' gemiddelde (170.6 cm)
    Let op: we bedoelen hier zowel groter dan 175.6 cm en kleiner dan 165.6 cm
              
Print de percentages op het scherm en gebruik 2 decimalen:
{: .language-python}
    Fractie afwijkende steekproeven voor N =   2: x.xx procent 
    Fractie afwijkende steekproeven voor N =   3: x.xx procent 
    Fractie afwijkende steekproeven voor N =   5: x.xx procent 
    Fractie afwijkende steekproeven voor N =  10: x.xx procent 
    Fractie afwijkende steekproeven voor N = 100: x.xx procent 

Extra: probeer de user te helpen door de getallen netjes uitgelijnd onder elkaar op het scherm te krijgen

Het is zeer inzichtelijk om de distributies van de gemiddeldes te bekijken voor de verschillende 
keuzes van de steekproefgrootte. Gebruik hiervoor de histogram methode die we ook in opgave 1 
gebruikt hebben. Kies zelf een geschikte bin-grootte.

**Conclusie:** Hoe groter de steekproef hoe beter het gemiddelde daarvan de 'echte' waarde 
benadert. Dat klinkt logisch, want het  maakt nogal uit of Maurice de Hond 10 mensen hun 
politieke voorkeur vraagt of 100000. Voor elk getal, meting of grafiek die je voortaan ziet, 
of dat nou in de krant, op de televisie of in een wetenschappelijk publicatie is, moet je 
je altijd afvragen wat de onzekerheid op die schatting is. Hoe kleiner de fout/onzekerheid, 
hoe belangrijker de meting is en hoe 'zwaarder' je de meting moet meewegen als je verschillende 
resultaten naast elkaar legt en een conclusie probeert te trekken. Een schatting zonder een 
foutmarge zegt dus niet zoveel.

## Fitten: wat zijn de parameters in je model die het best de data beschrijven

Om de onderliggende fenomenen van verschijnselen bloot te leggen en mogelijke verbanden te 
achterhalen verzamelen wetenschappers data. Dat kan de massa van het Higgs boson zijn, de 
halfwaardetijd van radioactieve elementen, maar ook het aantal kinderen in een gezin als functie 
van de gemiddelde lengte van de ouders of je reistijd per fiets naar de universiteit als 
functie van het moment op de dag. Elk meetpunt komt met een onzekerheid die de precisie 
aangeeft. Zoals we al gezien hebben: hoe kleiner de fout, hoe nauwkeuriger de meting en 
hoe 'belangrijker' het meetpunt is in het bepalen of dat data met je verwachtingen (model) 
overeenkomen. Als je eenmaal een goede beschrijving hebt gevonden van de verzamelde data dan 
kan je met dat model vervolgens voorspellingen doen in gebieden waar je nog niet gemeten hebt 
en tegelijkertijd werken aan een interpretatie van de reden van de correlatie.

We gaan in dit stuk van de module de de resultaten van een bovengenoemde fictieve onderzoek in 
detail bestuderen: de lengte van vrouwen als functie van het inkomen van haar ouders. Is er nou 
wel of niet verband te zien in de data? Om dat te bestuderen moeten we eerst van de verschillende 
hypotheses (wel of niet een verband) de parameters en hun onzekerheid bepalen. Het is inzichtelijk 
om de discussie over de manier waarop je de beste waarde van je parameters bepaalt (en de onzekerheid 
daarop) te voeren aan de hand van een voorbeeld. Na het voorbeeld (het kookpunt van alcohol) zullen we 
de kennis toepassen in een concrete opdracht die gerelateerd is aan onze casus.

### Voorbeeld: Bepalen kookpunt van alcohol tijdens het prakticum

Tijdens een prakticum kregen groepjes studenten de opdracht het kookpunt van alcohol te bepalen. 
Door gebrek aan tijd had elke groep maar tijd voor 1 meting. Er waren zes thermometer in de 
zaal die de temperatuur tot op 1 graad Celcius nauwkeurig konden bepalen en vier die dat konden 
met een hogere precisie, namelijk 0.5 graden. De lijst met de metingen van de tien groepen studenten 
is de volgende en de grafiek met de waardes staat weergegeven in de grafiek onderaan dit voorbeeld.

groepnummer (x)                      |  1   |  2   |  3   |  4   |  5   |  6   |  7   |  8   |  9   | 10 
gemeten kookpunt in $$^\circ$$C (y)  | 78.2 | 80.2 | 78.7 | 78.9 | 77.5 | 79.7 | 78.1 | 79.0 | 79.6 | 78.4 
onzekerheid ($$\sigma$$, fout op y)  |  1   |  1   |  1   |  0.5 |  1   |  1   |  0.5 |  0.5 |  1   | 0.5


#### [voorbeeld stap 1]: Model en doel van de exercitie
Het kookpunt van alcohol is een natuurconstante en hangt niet af van het groepje studenten dat de 
meting verricht. In dit geval is het 'model' dat we hebben een vlakke lijn en eigenijk proberen 
we dus de waarde van het kookpunt van alcohol te bepalen dat het best in overeenstemming is met 
de gemeten punten. Het is duidelijk dat 78$$^\circ$$ een betere schatting is dan 70$$^\circ$$ en 
79$$^\circ$$ een betere dan 81$$^\circ$$, maar wat is nou precies de 'beste' waarde? Kortom: wat 
is het gemiddelde van de hele klas?

#### [voorbeeld stap 2]: Een maat voor 'hoe goed' het model de data beschrijft: de $$\chi^2$$-maat

Om de 'beste' waarde te vinden hebben we een maat (metriek) nodig die de *goedheid* van de fit beschrijft. 
We doen dat hier met de zogenaamde $$\chi^2$$-maat (chi-kwadraat): de som van de gemiddelde afwijking van de 
meetpunten tot het model gewogen met hun fout. Voor elk punt bepalen we de afstand van de meting (uitgedrukt 
in de meetfout op het punt) tot de waarde die het model voorspelt op die plek. De som die afwijkingen voor 
elk meetpunt noemen we de $$\chi^2$$.

Iets formeler:
$$\chi^2(\vec{\alpha}) = \sum_{i~ {\rm (datapunten)}}  \left(\frac{  y_i - f(x_i|\vec{\alpha}) }{\sigma_i}\right)^2$$

In deze uitdrukking is $$\vec{\alpha}$$ de vector met de parameters die je gebruikt in je
model. Voor elke keuze van de parameters in je model verandert de afstand van elk meetpunt 
tot je model en krijg je dus een nieuwe $$\chi^2$$. 

Deze uitdrukking ziet er ingewikkelder uit:

   1. de $$\chi^2$$ is gewoon een getal

   2. in ons model is er maar 1 vrije parameter, namelijk het kookpunt van alcohol $$T_0$$.
      Ons model reduceert dan tot: $$f(x) = T_0$$ en de vector $$\vec{\alpha}$$ reduceert tot 1 parameter, de constante $$T_0$$. 
	  
#### [voorbeeld stap 3]: De beste waarde van de model-parameters vinden

In de fitprocedure zoeken we naar de waarde van de parameters in je model die
de kleinste $$\chi^2$$ oplevert omdat met die waarde van de parameters de 
meetpunten het dichtst bij het model in de buurt liggen. Met behulp van de computer 
gaan we verschillende waardes van $$T_0$$ proberen en voor elk de 
$$\chi^2$$ uitrekenen.
 
Als we bijvoorbeeld als hypothese $$T_0=78.0$$ nemen dan hoort daar de 
volgende $$\chi^2$$ bij:
$$
\begin{eqnarray}
   \chi^2(T_0=78.0)&=&    
   \tiny{
   \left( \frac{(78.2-78.0)}{1.0} \right)^2+
   \left( \frac{(80.2-78.0)}{1.0} \right)^2+
   \left( \frac{(78.7-78.0)}{1.0} \right)^2+
   \left( \frac{(78.9-78.0)}{0.5} \right)^2+
   \left( \frac{(77.5-78.0)}{1.0} \right)^2}\\
   &~& 
   \tiny{
  +\left( \frac{(79.7-78.0)}{1.0} \right)^2+
   \left( \frac{(78.1-78.0)}{0.5} \right)^2+
   \left( \frac{(79.0-78.0)}{0.5} \right)^2+
   \left( \frac{(79.6-78.0)}{1.0} \right)^2+
   \left( \frac{(78.4-78.0)}{0.5} \right)^2
   }\\
   &=&19.0
\end{eqnarray}
$$

Je kan nu verschillende waardes van $$T_0$$ proberen en voor elk de $$\chi^2$$
berekenen. De distributie is getekend in de rechterplot hieronder. Er is een
duidelijk minimum zichtbaar en de waarde van $$T_0$$ waarvoor de $$\chi^2$$ 
minimaal is noemen we $$T_0^{\rm best}=78.2$$.

#### [voorbeeld stap 4]: De onzekerheid op de parameters in je model

Elke waarde van je parameters die anders is dat $$T_0^{\rm best}$$ zal de waarde
van de $$\chi^2$$ veranderen (die wordt groter wat een slechtere overeenkomst
met de data betekent). Het verschil tussen de waarde van de $$T_0$$ waarbij
de $$\chi^2$$ precies 1 unit toeneemt en $$T_0^{\rm best}$$ noemen we de
onzekerheid op $$T_0$$. Dit wordt vaak omschreven als $$\Delta T_0$$. 
Bij het berekenen van de $$\chi^2$$ zien we dat er is het gebied is $$ 78.5 < T_0 <78.9$$ 
waarvoor de $$\chi^2$$ minder dan 1 unit verschilt van $$\chi^2_{min}$$. Het resultaat 
van de fit, en dus het result van de gecombineerde schattig van het kookpunt van alcohol 
door de hele groep  studenten samen wordt gegeven door:

   Kookpunt alcohol = $$78.2 \pm 0.2 ^\circ C$$
   
**Let op:** Hoewel we hier aannemen dat de fout in $$T_0$$ symmetrisch is hoeft dat niet
altijd het geval te zijn. Evalueer dus altijd de negatieve en positieve fout afzonderlijk 
door te kijken hoe de $$\chi^2$$ verandert als je de parameters respectievelijk kleiner en 
groter maakt.

#### [voorbeeld stap 5]: de bijbehorende plots

![](FitExampleWebsite.png){: style="width:90%"}


Het voorbeeld dat we hier hebben uitgewerkt is het zogenaamd 'fitten' van een simpel 
model met 1 parameter aan de data. Ook als we een ingewikkelder model hebben, bijvoorbeeld 
een eerstegraads polynoom, $$f(x)=ax+b$$, dan vinden we ook de beste waarde van de twee 
parameters door $$a$$ en $$b$$ te varieren en te kijken voor welke waarden de $$\chi^2$$ 
minimaal is.

## Opdracht 3: gemiddelde lengte vrouwen in Denemarken

In Denemarken is een onderzoeksgroep dus aan het onderzoeken of de lengte van vrouwen gecorreleerd is met het 
inkomens van hun ouders. Er is gekozen voor 10 inkomenscategorieen en hoewel er geprobeerd is zoveel mogelijk 
gelijke aantallen vrouwen per categorie op te nemen in de studie is het aantal vrouwen met ouders in de 
extremen van de inkomstengroepen (erg rijk en erg arm) helaas beperkt. Dit is duidelijk door de grotere fout 
op de schatting van de gemiddelde lengte in die groepen.

Categorie (x)        |  1 (arm)   |  2    |  3    |  4    |  5    |  6    |  7    |  8    |  9    | 10 (rijk)
Gem. lengte (y)      | 171.1 | 169.1 | 170.8 | 169.4 | 173.0 | 171.0 | 174.0 | 174.0 | 173.0 | 176.0 
Fout ($$\Delta y$$)  |  4    |  4    |  2    |  2    |  2    |  2    |  2    |  2    |  4    |  4

Schrijf een programma `statistiek_opdracht3.py()` waarin je het gemiddelde vindt van de lengte van vrouwen 
in Denemarken door een fit te maken aan de hierboven gegeven data met de functie $$f(x) = C$$. Je neemt dus 
aan in deze opgave dat er geen correlatie is tussen het inkomen van de ouders en de lengte van hun dochters. 
Volg hierbij de stappen in het voorbeeld over het meten van het kookpunt van alcohol zoals hierboven is besproken. 
Zorg dat je programma de data (met fouten) op het scherm weergeeft en ook de beste waarde van de fit die je 
gevonden hebt. Dus net zoals de linkerplot in het voorbeeld hierboven. Gebruik voor het plotten van de data met 
fouten de Python functie `plt.errorbar(x,y, yerr=yerror)`. Zoek op internet op hoe je deze functie moet gebruiken. 

Print je resultaat, met 1 decimaal precisie, op de volgende manier naar het scherm:
{: .language-python}
    De fit (vlakke lijn) geeft een gemiddelde lengte van xxx.x cm


## Opdracht 4: Een iets complexer model: f(x) = ax+b en fits in Python zelf 

Iemand in de onderzoeksgroep heeft geopperd dat er welleens een (lineair) verband zou kunnen zijn tussen 
de lengte van mensen en het inkomen van hun ouders. Dat zou verschillende oorzaken kunnen hebben. Dat is 
voor later. De eerste stap in het onderzoek is om eerst te bekijken of er uberhaupt een verband is. We 
gaan proberen een verband te vinden in de data.

Een vlakke lijn fitten is alleen toepasselijk als er geen afhankelijkheid is tussen de variabelen. In de meeste 
gevallen is dat wel het geval: hoogte zeeniveau als functie van de tijd (sinus), aantal vervallen van een radioactief 
element (exponentieel) of de snelheid van planeten als functie van hun afstand tot de zon (omgekeerd evenredig met 
de wortel van de afstand tot de zon). Ook in die gevallen volgen we hetzelfde procede: varieer de parameters tot de 
$$\chi^2$$ minimaal is. Het fitten van een model aan metingen is een standaard procedure die je als onderzoeker vaak 
tegen zult komen als je verschillende hypotheses wilt testen of de onderliggende dynamica bloot wilt leggen. Het 
implementeren van een fit in een model met meerdere (gecorreleerde) parameters wordt al snel erg complex en kost 
enorm veel rekenkracht tenzij je het slim aanpakt. Net als in bijna elke programmeertaal zijn er bibliotheken vol 
functies in Python die je daarmee kunnen helpen. Hoewel we in deze cursus deze functionaliteit en alle bijbehorende 
details niet verder zullen gebruiken door gebrek aan tijd, willen we hier toch een voorbeeld geven waarin je ziet hoe 
dat in de praktijk gaat.

#### Fitten in Python: f(x) = C (1 vrijheidsgraad)

    # import the module that contains the fit-tool
    from scipy.optimize import curve_fit

    # define our model. In our case a constant function: f(x) = a 
    def MyFitFunction(x, a):
        return a

    # define data and errors
    data_x       = [1,2,3,4,5,6,7,8,9,10]
    data_y       = [171.2, 169.1, 170.8, 169.4, 173, 171, 174, 174, 173, 176]
    data_y_error = [4,4,2,2,2,2,2,2,4,4]
    
    popt, pcov = curve_fit(MyFitFunction, data_x, data_y, None, data_y_error)
    print "Best value: f(x) = %5.2f" % popt[0]

De laatste regel blijft nu nog magie, maar `popt` is een lijst met de 'optimale' 
parameters van de functie die je aan de data hebt gefit. In ons geval is dat maar 
1 parameter omdat we een constante functie aanhouden als model. Je kan zelf in de 
documentatie opzoeken hoe je zelf uit `pcov` (de covariantiematrix) de onzekerheid 
op de parameter kan bepalen. 

#### Fitten in Python: f(x) = ax+ b (2 vrijheidsgraden)

Als je nu in plaats van een constante functie een lineaire functie wilt fitten 
$$f(x) = ax+b$$ en je wilt de resultaten printen dan hoef je maar op 2 plekken een 
verandering aan te brengen. Op de plek waar je de functie die je fit definieert en 
op de plek waar je de resultaten print naar het scherm. Zoek ze maar op.

    # import the module that contains the fit-tool
    from scipy.optimize import curve_fit

    # define our model. In our case a constant function: f(x) = a*x + b 
    def MyFitFunction(x, a, b):
        return a * x + b

    # define data and errors
    data_x       = [1,2,3,4,5,6,7,8,9,10]
    data_y       = [171.2, 169.1, 170.8, 169.4, 173, 171, 174, 174, 173, 176]
    data_y_error = [4,4,2,2,2,2,2,2,4,4]
    
    popt, pcov = curve_fit(MyFitFunction, data_x, data_y, None, data_y_error)
    print "Best value: f(x) = %5.2f * x + %5.2f" % (popt[0], popt[1])

#### Opdracht 4: een fit aan de data met als model: f(x) = ax+b 

Schrijf een programma `statistiek_opdracht4.py()` waarin je zowel een rechte lijn als een lineair 
verband fit aan de data. Gebruik hiervoor de tools in Python zoals hierboven beschreven en reproduceer 
de grafiek die helemaal aan het begin van deze module werd getoond. Laat dus zowel de data als de 
beide 'beste' functies in de grafiek zien. Zorg hierbij ook dat de waardes van de parameters worden 
weergegeven. Print de waardes ook op het scherm als output:

{: .language-python}
    Een fit van f(x)=c     geeft als beste waarde:  c = x.xx
    Een fit van f(x)=ax+b  geeft als beste waardes: a = x.xx  en b = x.xx
	

## Opdracht 5: Hypotheses testen

Een deel van de onderzoekers vindt dat de data suggereert dat er een lineair verband te 
zien is in de data terwijl een ander deel vindt dat er geen afhankelijkheid is en dat de 
geobserveerde lichte afhankelijkheid gewoon toeval is door de steekproeven die genomen zijn. 
We sluiten deze module af door wat quantitatieve data aan te leveren voor dee discussie.

De vraag is eigenlijk: "hoe zeldzaam is dat, gegeven dat er in het echt <b>geen</b> verband bestaat, 
een serie steekproeven (van deze grootte in elke categorie) een waarde van de richtingscoefficient 
geeft die net zo groot is als in de data of zelfs nog groter?" Deze fractie kom je vaak tegen in de 
literatuur en wordt ook wel de <font color = 'red'> p-waarde </font>genoemd.

#### opdracht 5: Simuleer random data-sets en bereken de p-waarde

Schrijf een programma `statistiek_opdracht5.py()` die bovenstaande vraag beantwoordt door te kijken 
hoe zeldzaam de geobserveerde richtingscoefficient in de data is als er eigenlijk helemaal geen 
afhankelijkheid is.

Volg om de vraag te beantwoorden de volgende strategie:

   1. Simuleer een data-set:

       * Ga uit van 'vlakke' verdeling: f(x) = C, met C de waarde uit opdracht 3.

	   * Kies in elke inkomensgroep een 'random' meetpunt door gebruik te maken van 
     	 `numpy.random.normal(gemiddelde,breedte)`, waarbij het gemiddelde gegeven wordt 
		 door de waarde die je in opdracht 3 vond. Gebruik als breedte de onzekerheid op 
		 de gemiddelde lengte in die in komensgroep in de oorspronkelijke data-set. Dat is 
		 dus bijvoorbeeld 4 cm in inkomenscategorie 1.
		
	   * Geef als fout op de random gekozen gemiddelde lengte in elke inkomensgroep dezelfde 
	     fout als in de oorspronkelijke inkomensgroep. Dat is dus bijvoorbeeld 2 cm in 
		 inkomenscategorie 5.
	   
   2. Fit een functie van de vorm f(x) = ax+b en bepaal de richtingscoefficient (a).

   3. Doe bovenstaande een groot aantal keer (10000 keer bijvoorbeeld) en onthoud voor elke 
      data-set de richtingscoefficient. Hou bij het simuleren ook bij welke fractie van de 
	  gesimuleerde data-sets (toevallig) een richtingscoefficient opleverden die gelijk was 
	  aan (of nog groter was dan) die in de originele data-set (zie opdracht 4).  

   4. Maak een grafiek (histogram, zie hieronder) van alle richtingscoefficenten en geef duidelijk 
      aan wat de gevonden waarde is in de data en de bijbehorende p-waarde. 
	  
      ![](ExamplePvalue.png){: style="width:60%"}

   5. Print de p-waarde aan het eind van het programma ook op het scherm: in procenten, met 2 decimalen.
    
      {: .language-python}
     	De p-waarde voor de alternatieve hypothese = x.xx procent


In de regel houden we vast aan de regel dat als de p-waarde kleiner is dan 5 procent we nog van 
'toeval' spreken. Is de p-waarde groter dan 5% dan zeggen we dat de geobserveerde trend niet goed 
te verklaren valt met een vlakke hypothese en dat we bewijs hebben gevonden voor een verband.

*Let op:* Een gevonden verband is nog geen causaal verband. Stel dat er een verband is gevonden 
(en hou altijd in het achterhoofd dat het geobserveerde effect alsnog toeval kan zijn), wat zou 
dan de onderliggende oorzaak kunnen zijn ? Rijkere mensen: eten gezonder, wonen in huizen die 
in een buurt liggen met betere luchtkwaliteit, of andersom dat in onze maatschappij de 
lengte juist zorgt voor een hogere inkomen ? Etc etc. Graven graven graven tot je doordringt tot 
de kern en iets nieuws ontdekt dat nog niemand voor jou gezien heeft. Dat is wetenschap!



# Bonusvraag: bèta's als bankiers in the City (Quants)

Bij veel banken en verzekeraars werken wis- en natuurkundigen: in de zogenaamde risk-analysis departments, 
maar ook als quantitatieve analysten: quants. Laten dat zelf ook eens proberen door de eindstand van de 
AEX te voorspellen in het jaar 2000 door gebruik te maken van de jaren ervoor: 1991-1999.

De eindstand van de AEX kan je vinden op de [AEX wiki](https://nl.wikipedia.org/wiki/AEX):

![](AEXeindstandTabel.png)

### BonusOpdracht: voorspel de AEX einstand in het jaar 2000

Schrijf een programma `StatistiekBonus.py()` waarin je de eindstand van de AEX voorspelt in 
het jaar 2000 op grond van de waardes aan het eind van 1991-1999. Volg hierbij de volgende stappen:

   1. Maak een grafiek van de eindstand van de AEX als functie van het jaar sinds 1991.

   2. Fit de meetpunten met een 2$$^{\rm e}$$ graads polynoom: $$f(x)=ax^2+bx+c$$. 
      Pas de fit-functie aan die we eerder in deze module gebruikt hebben. 
    
Zodra je de functie hebt gevonden die de data-punten goed gebruikt heb je een model waarmee je 
ook kan extrapoleren. Wat is je voorspelling voor de eindstand van de AEX in het jaar 2000? 
Vergelijk deze met de echte waarde die gerealiseerd werd (637,60). En? Hoe kan dat?


	
	
